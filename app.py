import streamlit as st
import os
import google.generativeai as genai
import edge_tts
import asyncio
import tempfile
import time
from moviepy.editor import VideoFileClip, AudioFileClip, vfx

# --- INITIAL SETUP ---
st.set_page_config(page_title="Burmese Movie Recap AI", layout="wide")
st.title("ğŸ¬ Burmese Movie Recap AI")

# API Key - Secrets á€‘á€²á€™á€¾á€¬ á€™á€›á€¾á€­á€›á€„á€º á€¡á€±á€¬á€€á€ºá€€ Key á€€á€­á€¯ á€á€¯á€¶á€¸á€™á€šá€º
GEMINI_API_KEY = st.secrets.get("GEMINI_API_KEY", "AIzaSyBDfSFCV4kF56dAZ8Zx0m0xaR8a40v8pG4")

# á€•á€¼á€¿á€”á€¬á€¡á€›á€¾á€­á€†á€¯á€¶á€¸á€–á€¼á€…á€ºá€á€²á€· API Version á€€á€­á€¯ Stable á€–á€¼á€…á€ºá€á€²á€· v1 á€á€­á€¯á€· á€•á€¼á€±á€¬á€„á€ºá€¸á€œá€²á€á€¼á€„á€ºá€¸
os.environ["GOOGLE_GENERATIVE_AI_API_VERSION"] = "v1"
genai.configure(api_key=GEMINI_API_KEY)

def analyze_video(video_path):
    try:
        # Model Name á€€á€­á€¯ á€¡á€á€­á€¡á€€á€» á€•á€¼á€±á€¬á€„á€ºá€¸á€œá€²á€‘á€¬á€¸á€•á€«á€á€Šá€º
        model = genai.GenerativeModel(model_name='models/gemini-1.5-flash')
        
        with st.spinner("AI á€€ á€—á€®á€’á€®á€šá€­á€¯á€€á€­á€¯ á€…á€…á€ºá€†á€±á€¸á€”á€±á€•á€«á€á€Šá€º..."):
            video_file = genai.upload_file(path=video_path)
            
            while video_file.state.name == "PROCESSING":
                time.sleep(2)
                video_file = genai.get_file(video_file.name)
            
            if video_file.state.name == "FAILED":
                return "Video processing failed."

            prompt = "á€‡á€¬á€á€ºá€œá€™á€ºá€¸á€…á€…á€á€»á€„á€ºá€¸á€™á€¾á€¬... á€†á€­á€¯á€á€²á€· á€…á€€á€¬á€¸á€œá€¯á€¶á€¸á€”á€²á€· á€…á€á€„á€ºá€•á€¼á€®á€¸ á€’á€®á€—á€®á€’á€®á€šá€­á€¯á€€á€­á€¯ á€…á€­á€á€ºá€á€„á€ºá€…á€¬á€¸á€…á€›á€¬á€€á€±á€¬á€„á€ºá€¸á€¡á€±á€¬á€„á€º á€™á€¼á€”á€ºá€™á€¬á€œá€­á€¯ Movie Recap á€‡á€¬á€á€ºá€Šá€½á€¾á€”á€ºá€¸ á€›á€±á€¸á€•á€±á€¸á€•á€«á‹"
            response = model.generate_content([video_file, prompt])
            return response.text
    except Exception as e:
        return f"Error: {str(e)}"

async def generate_voice(text, output_path):
    communicate = edge_tts.Communicate(text, "my-MM-ThihaNeural")
    await communicate.save(output_path)

# --- UI ---
uploaded_file = st.file_uploader("á€—á€®á€’á€®á€šá€­á€¯á€–á€­á€¯á€„á€ºá€á€„á€ºá€•á€«", type=['mp4', 'webm', 'mov'])

if uploaded_file:
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as tfile:
        tfile.write(uploaded_file.read())
        input_path = tfile.name

    if st.button("Recap á€œá€¯á€•á€ºá€™á€Šá€º"):
        # 1. Script
        script_text = analyze_video(input_path)
        
        if "Error" in script_text:
            st.error(f"AI á€€ á€¡á€†á€„á€ºá€™á€•á€¼á€±á€–á€¼á€…á€ºá€”á€±á€•á€«á€á€Šá€º: {script_text}")
        else:
            st.subheader("ğŸ“ Recap Script (Burmese)")
            st.write(script_text)

            # 2. Voice
            with st.spinner("á€¡á€á€¶á€–á€­á€¯á€„á€º á€•á€¼á€±á€¬á€„á€ºá€¸á€œá€²á€”á€±á€á€Šá€º..."):
                asyncio.run(generate_voice(script_text, "voice.mp3"))
            
            # 3. Final Video
            try:
                with st.spinner("á€—á€®á€’á€®á€šá€­á€¯ á€•á€±á€«á€„á€ºá€¸á€…á€•á€ºá€”á€±á€á€Šá€º..."):
                    v_clip = VideoFileClip(input_path).without_audio()
                    a_clip = AudioFileClip("voice.mp3")
                    # Speed adjustment
                    speed = v_clip.duration / a_clip.duration
                    final_video = v_clip.fx(vfx.speedx, speed).set_audio(a_clip)
                    final_video.write_videofile("recap_done.mp4", codec="libx264")
                    st.video("recap_done.mp4")
            except Exception as e:
                st.error(f"Video Merge Error: {e}")
