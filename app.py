import streamlit as st
import os
import cv2
import numpy as np
from moviepy.editor import VideoFileClip, AudioFileClip, vfx
import google.generativeai as genai
import edge_tts
import asyncio
import tempfile
import time

# --- CONFIGURATION ---
GEMINI_API_KEY = st.secrets.get("GEMINI_API_KEY", "AIzaSyBDfSFCV4kF56dAZ8Zx0m0xaR8a40v8pG4")
genai.configure(api_key=GEMINI_API_KEY)

st.set_page_config(page_title="Auto Burmese Movie Recap AI", layout="wide")

# --- FUNCTIONS ---
def adjust_video_sync(video_path, audio_path, output_path):
    try:
        video_clip = VideoFileClip(video_path).without_audio()
        audio_clip = AudioFileClip(audio_path)
        speed_factor = video_clip.duration / audio_clip.duration
        final_video = video_clip.fx(vfx.speedx, speed_factor).set_audio(audio_clip)
        final_video.write_videofile(output_path, codec="libx264", audio_codec="aac", fps=24)
        return output_path
    except Exception as e:
        st.error(f"Video Processing Error: {e}")
        return None

def apply_blur_to_video(video_path, output_path):
    cap = cv2.VideoCapture(video_path)
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    fps = cap.get(cv2.CAP_PROP_FPS) or 24
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret: break
        out.write(frame)
    cap.release(); out.release()
    return output_path

async def generate_voice(text, output_path):
    communicate = edge_tts.Communicate(text, "my-MM-ThihaNeural")
    await communicate.save(output_path)

def analyze_and_recap(video_file_path):
    # Model á€”á€¬á€™á€Šá€ºá€€á€­á€¯ á€”á€Šá€ºá€¸á€”á€Šá€ºá€¸á€•á€¼á€±á€¬á€„á€ºá€¸á€•á€¼á€®á€¸ á€…á€™á€ºá€¸á€€á€¼á€Šá€·á€ºá€•á€«á€™á€Šá€º
    try:
        model = genai.GenerativeModel('gemini-1.5-flash-latest') # Flash á€”á€±á€¬á€€á€ºá€†á€¯á€¶á€¸á€‘á€½á€€á€º
    except:
        model = genai.GenerativeModel('gemini-1.5-pro') # Flash á€™á€›á€›á€„á€º Pro á€€á€­á€¯á€á€¯á€¶á€¸á€™á€šá€º
    
    with st.spinner("AI á€€ á€—á€®á€’á€®á€šá€­á€¯á€€á€­á€¯ á€–á€á€ºá€›á€¾á€¯á€”á€±á€á€Šá€º (á€™á€­á€”á€…á€ºá€¡á€”á€Šá€ºá€¸á€„á€šá€º á€€á€¼á€¬á€”á€­á€¯á€„á€ºá€•á€«á€á€Šá€º)..."):
        video_file = genai.upload_file(path=video_file_path)
        
        # Processing state á€€á€­á€¯ á€…á€±á€¬á€„á€·á€ºá€á€¼á€„á€ºá€¸
        while video_file.state.name == "PROCESSING":
            time.sleep(2)
            video_file = genai.get_file(video_file.name)
            
        if video_file.state.name == "FAILED":
            raise ValueError("Video processing failed.")

    prompt = "Listen to the audio, translate to Burmese and write a dramatic movie recap script. Start with 'á€‡á€¬á€á€ºá€œá€™á€ºá€¸á€…á€…á€á€»á€„á€ºá€¸á€™á€¾á€¬...' Burmese only."
    
    # API Version Error á€á€€á€ºá€›á€„á€º á€”á€±á€¬á€€á€ºá€á€…á€ºá€™á€»á€­á€¯á€¸ á€•á€¼á€±á€¬á€„á€ºá€¸á€…á€™á€ºá€¸á€™á€šá€·á€º logic
    try:
        response = model.generate_content([video_file, prompt])
    except Exception as e:
        st.warning(f"Flash model error: {e}. Switching to Pro model...")
        model_pro = genai.GenerativeModel('gemini-1.5-pro')
        response = model_pro.generate_content([video_file, prompt])

    return response.text

# --- UI ---
st.title("ğŸ¬ Burmese Movie Recap AI")
st.caption("Using Gemini 1.5 Flash/Pro")

uploaded_file = st.file_uploader("á€—á€®á€’á€®á€šá€­á€¯á€–á€­á€¯á€„á€ºá€á€„á€ºá€•á€«", type=['mp4', 'webm', 'mov', 'avi'])

if uploaded_file:
    suffix = os.path.splitext(uploaded_file.name)[1]
    with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tfile:
        tfile.write(uploaded_file.read())
        temp_path = tfile.name
    
    if st.button("Recap á€œá€¯á€•á€ºá€™á€Šá€º"):
        try:
            # 1. Script
            script = analyze_and_recap(temp_path)
            st.success("á€‡á€¬á€á€ºá€Šá€½á€¾á€”á€ºá€¸á€›á€›á€¾á€­á€•á€«á€•á€¼á€®!")
            st.write(script)
            
            # 2. Voice
            asyncio.run(generate_voice(script, "voice.mp3"))
            
            # 3. Video
            with st.spinner("á€—á€®á€’á€®á€šá€­á€¯á€€á€­á€¯ á€•á€±á€«á€„á€ºá€¸á€…á€•á€ºá€”á€±á€á€Šá€º..."):
                final_path = "final_recap.mp4"
                # á€›á€­á€¯á€¸á€›á€¾á€„á€ºá€¸á€¡á€±á€¬á€„á€º Blur á€™á€œá€¯á€•á€ºá€˜á€² á€á€­á€¯á€€á€ºá€›á€­á€¯á€€á€ºá€•á€±á€«á€„á€ºá€¸á€…á€•á€ºá€€á€¼á€Šá€·á€ºá€™á€Šá€º (Error á€œá€»á€±á€¬á€·á€”á€Šá€ºá€¸á€¡á€±á€¬á€„á€º)
                adjust_video_sync(temp_path, "voice.mp3", final_path)
                
            st.video(final_path)
            
        except Exception as e:
            st.error(f"Error á€–á€¼á€…á€ºá€•á€½á€¬á€¸á€•á€«á€á€Šá€º: {e}")
            if os.path.exists(temp_path): os.remove(temp_path)
